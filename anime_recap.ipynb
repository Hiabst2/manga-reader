{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8dec17-bddc-409a-8610-c0ab1a57ed15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from elevenlabs.client import AsyncElevenLabs\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "\n",
    "from manga_extraction import extract_all_pages_as_images, save_important_pages, split_volume_into_parts, save_all_pages\n",
    "from vision_analysis import analyze_images_with_gpt4_vision, detect_important_pages, VISION_PRICE_PER_TOKEN \n",
    "from prompts import DRAMATIC_PROMPT, BASIC_PROMPT, BASIC_PROMPT_WITH_CONTEXT,  BASIC_INSTRUCTIONS, KEY_PAGE_IDENTIFICATION_INSTRUCTIONS\n",
    "from citation_processing import extract_text_and_citations, extract_script\n",
    "from movie_director import make_movie\n",
    "from panel_extractor.panel_extractor import PanelExtractor\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca43991-2e27-4c95-9a6f-f2974e0b6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_number = 10\n",
    "manga = \"naruto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bbe703-0967-473f-b58c-663e05afabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all pages from the volume...\n",
      "Total pages in volume: 177\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client with API key\n",
    "client = OpenAI()\n",
    "# get elevenlabs api key from dotenv\n",
    "narration_client = AsyncElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n",
    "\n",
    "print(\"Extracting all pages from the volume...\")\n",
    "volume_scaled_and_unscaled = extract_all_pages_as_images(f\"{manga}/v{volume_number}/v{volume_number}.pdf\")\n",
    "volume = volume_scaled_and_unscaled[\"scaled\"]\n",
    "print(\"Total pages in volume:\", len(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8aa7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = save_all_pages(volume_scaled_and_unscaled[\"full\"], manga, volume_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e2d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load text detector ... Done!\n",
      "Loading images ... Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing images with paper texture: 100%|██████████| 177/177 [00:01<00:00, 90.64it/s]\n",
      "Detecting text:   1%|          | 1/154 [00:02<07:27,  2.92s/it]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m panel_extractor \u001b[38;5;241m=\u001b[39m PanelExtractor(keep_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_pct_panel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_pct_panel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpanel_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/panel_extractor.py:120\u001b[0m, in \u001b[0;36mPanelExtractor.extract\u001b[0;34m(self, folder)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# remove text from panels\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_text:\n\u001b[0;32m--> 120\u001b[0m     paperless_imgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaperless_imgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(paperless_imgs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracting panels\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    123\u001b[0m     panels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_panels(img)\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/panel_extractor.py:67\u001b[0m, in \u001b[0;36mPanelExtractor.remove_text\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# detect text\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoving text ... \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m     text_masks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/text_detector/main_text_detector.py:39\u001b[0m, in \u001b[0;36mTextDetector.detect\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDetecting text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/text_detector/main_text_detector.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(imgs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetecting text\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/text_detector/main_text_detector.py:67\u001b[0m, in \u001b[0;36mTextDetector.test_net\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# coordinate adjustment\u001b[39;00m\n\u001b[1;32m     66\u001b[0m boxes \u001b[38;5;241m=\u001b[39m adjustResultCoordinates(boxes, ratio_w, ratio_h)\n\u001b[0;32m---> 67\u001b[0m polys \u001b[38;5;241m=\u001b[39m \u001b[43madjustResultCoordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(polys)):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m polys[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Melden/reader-manga/panel_extractor/text_detector/craft_utils.py:239\u001b[0m, in \u001b[0;36madjustResultCoordinates\u001b[0;34m(polys, ratio_w, ratio_h, ratio_net)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjustResultCoordinates\u001b[39m(polys, ratio_w, ratio_h, ratio_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(polys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 239\u001b[0m         polys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(polys)\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(polys)):\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m polys[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "panel_extractor = PanelExtractor(keep_text=True, min_pct_panel=2, max_pct_panel=90)\n",
    "panel_extractor.extract(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35d189-d3d8-445e-ad4d-dc94060b4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_reference = extract_all_pages_as_images(f\"{manga}/profile-reference.pdf\")[\"scaled\"]\n",
    "chapter_reference = extract_all_pages_as_images(f\"{manga}/chapter-reference.pdf\")[\"scaled\"]\n",
    "\n",
    "profile_pages = []\n",
    "chapter_pages = [] \n",
    "\n",
    "important_page_tokens = 0\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "print(\"Identifying important pages in the volume...\")\n",
    "# Function to wrap the detect_important_pages call\n",
    "def process_batch(start_idx, pages):\n",
    "    response = detect_important_pages(profile_reference, chapter_reference, pages, client,\n",
    "        KEY_PAGE_IDENTIFICATION_INSTRUCTIONS, KEY_PAGE_IDENTIFICATION_INSTRUCTIONS)\n",
    "    return start_idx, response\n",
    "\n",
    "# Using ThreadPoolExecutor to parallelize API calls\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for i in range(0, len(volume), batch_size):\n",
    "        pages = volume[i:i+batch_size]\n",
    "        futures.append(executor.submit(process_batch, i, pages))\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        start_idx, response = future.result()\n",
    "        end_index = start_idx + batch_size - 1\n",
    "        print(f\"Processing pages {start_idx} to {min(end_index, len(volume)-1)}\")\n",
    "        \n",
    "        ip = response[\"parsed_response\"]\n",
    "        print(json.dumps(ip, indent=2))\n",
    "        for page in ip:\n",
    "            if page[\"type\"] == \"profile\":\n",
    "                profile_pages.append(page[\"image_index\"] + start_idx)\n",
    "            elif page[\"type\"] == \"chapter\":\n",
    "                chapter_pages.append(page[\"image_index\"] + start_idx)\n",
    "\n",
    "        important_page_tokens += response[\"total_tokens\"]\n",
    "\n",
    "profile_pages.sort()\n",
    "chapter_pages.sort()\n",
    "\n",
    "print(\"Total tokens to extract profiles and chapters:\", important_page_tokens)\n",
    "print(\"\\n__________\\n\")\n",
    "print(\"Profile pages:\", profile_pages)\n",
    "print(\"Chapter pages:\", chapter_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780436d6-8bdc-4b04-a11d-348eb9638225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n__________\\n\")\n",
    "print(\"Saving important pages to disk for QA...\")\n",
    "save_important_pages(volume, profile_pages, chapter_pages, manga, volume_number)\n",
    "\n",
    "\n",
    "character_profiles = [volume[i] for i in profile_pages]    \n",
    "jobs = split_volume_into_parts(volume, chapter_pages, 5)\n",
    "\n",
    "# Summarize the images in the first job\n",
    "response = analyze_images_with_gpt4_vision(character_profiles, jobs[0], client, BASIC_PROMPT, BASIC_INSTRUCTIONS)\n",
    "recap = response.choices[0].message.content\n",
    "tokens = response.usage.total_tokens\n",
    "movie_script = extract_text_and_citations(response.choices[0].message.content, jobs[0])\n",
    "\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# iterate thrugh the rest of the jobs while adding context from previous ones\n",
    "for job in jobs[1:]:\n",
    "    response = analyze_images_with_gpt4_vision(character_profiles, job, client, recap + \"\\n-----\\n\" + BASIC_PROMPT_WITH_CONTEXT, BASIC_INSTRUCTIONS)\n",
    "    recap = recap + \"\\n\\n\" + response.choices[0].message.content\n",
    "    tokens += response.usage.total_tokens\n",
    "    print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "    print(response.choices[0].message.content)\n",
    "    movie_script = movie_script + extract_text_and_citations(response.choices[0].message.content, job)\n",
    "\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "\n",
    "narration_script = extract_script(movie_script)\n",
    "print(narration_script)\n",
    "print(\"\\n___________\\n\")\n",
    "\n",
    "ELEVENLABS_PRICE_PER_CHARACTER = 0.0003\n",
    "print(\"Tokens for extracting profiles and chapters:\", important_page_tokens, \" | \", \"${:,.4f}\".format(VISION_PRICE_PER_TOKEN * important_page_tokens))\n",
    "print(\"Tokens for summarization:\", tokens,  \" | \", \"${:,.4f}\".format(VISION_PRICE_PER_TOKEN * tokens))\n",
    "print(\"Total GPT tokens:\", important_page_tokens + tokens,  \" | \", \"${:,.4f}\".format(VISION_PRICE_PER_TOKEN * (tokens+important_page_tokens)))\n",
    "print(\"Total elevenlabs characters:\", len(narration_script), \" | \", \"${:,.4f}\".format(ELEVENLABS_PRICE_PER_CHARACTER * (len(narration_script))))\n",
    "print(\"GRAND TOTAL COST\",\" | \", \"${:,.4f}\".format(VISION_PRICE_PER_TOKEN * (tokens+important_page_tokens) + ELEVENLABS_PRICE_PER_CHARACTER * (len(narration_script))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await make_movie(movie_script, manga, volume_number, narration_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcb9d2-bf68-4d18-b475-c52145efdd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebb25c-7473-4f55-b20b-0eff66908581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d4cc7-37a5-44d3-9480-b98dae3c8289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7aac2-9860-4eb8-8d54-8a4c34702fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33283437-1e28-43a8-b067-b7b13c412bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6edb8-6850-4418-87aa-b9496e4d140d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
