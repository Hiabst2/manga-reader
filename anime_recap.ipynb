{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8dec17-bddc-409a-8610-c0ab1a57ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from elevenlabs.client import AsyncElevenLabs\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "\n",
    "from manga_extraction import extract_all_pages_as_images, save_important_pages, split_volume_into_parts, save_all_pages, extract_panels, scale_base64_image\n",
    "from vision_analysis import analyze_images_with_gpt4_vision, detect_important_pages, get_important_panels, VISION_PRICE_PER_TOKEN \n",
    "from prompts import DRAMATIC_PROMPT, BASIC_PROMPT, BASIC_PROMPT_WITH_CONTEXT,  BASIC_INSTRUCTIONS, KEY_PAGE_IDENTIFICATION_INSTRUCTIONS, KEY_PANEL_IDENTIFICATION_PROMPT, KEY_PANEL_IDENTIFICATION_INSTRUCTIONS\n",
    "from citation_processing import extract_text_and_citations, extract_script\n",
    "from movie_director import make_movie\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca43991-2e27-4c95-9a6f-f2974e0b6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_number = 102\n",
    "manga = \"naruto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbe703-0967-473f-b58c-663e05afabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client with API key\n",
    "client = OpenAI()\n",
    "# get elevenlabs api key from dotenv\n",
    "narration_client = AsyncElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n",
    "\n",
    "print(\"Extracting all pages from the volume...\")\n",
    "volume_scaled_and_unscaled = extract_all_pages_as_images(f\"{manga}/v{volume_number}/v{volume_number}.pdf\")\n",
    "volume = volume_scaled_and_unscaled[\"scaled\"]\n",
    "volume_unscaled = volume_scaled_and_unscaled[\"full\"]\n",
    "print(\"Total pages in volume:\", len(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35d189-d3d8-445e-ad4d-dc94060b4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_reference = extract_all_pages_as_images(f\"{manga}/profile-reference.pdf\")[\"scaled\"]\n",
    "chapter_reference = extract_all_pages_as_images(f\"{manga}/chapter-reference.pdf\")[\"scaled\"]\n",
    "\n",
    "profile_pages = []\n",
    "chapter_pages = [] \n",
    "\n",
    "important_page_tokens = 0\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "print(\"Identifying important pages in the volume...\")\n",
    "# Function to wrap the detect_important_pages call\n",
    "def process_batch(start_idx, pages):\n",
    "    response = detect_important_pages(profile_reference, chapter_reference, pages, client,\n",
    "        KEY_PAGE_IDENTIFICATION_INSTRUCTIONS, KEY_PAGE_IDENTIFICATION_INSTRUCTIONS)\n",
    "    return start_idx, response\n",
    "\n",
    "# Using ThreadPoolExecutor to parallelize API calls\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for i in range(0, len(volume), batch_size):\n",
    "        pages = volume[i:i+batch_size]\n",
    "        futures.append(executor.submit(process_batch, i, pages))\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        start_idx, response = future.result()\n",
    "        end_index = start_idx + batch_size - 1\n",
    "        print(f\"Processing pages {start_idx} to {min(end_index, len(volume)-1)}\")\n",
    "        \n",
    "        ip = response[\"parsed_response\"]\n",
    "        print(json.dumps(ip, indent=2))\n",
    "        for page in ip:\n",
    "            if page[\"type\"] == \"profile\":\n",
    "                profile_pages.append(page[\"image_index\"] + start_idx)\n",
    "            elif page[\"type\"] == \"chapter\":\n",
    "                chapter_pages.append(page[\"image_index\"] + start_idx)\n",
    "\n",
    "        important_page_tokens += response[\"total_tokens\"]\n",
    "\n",
    "profile_pages.sort()\n",
    "chapter_pages.sort()\n",
    "\n",
    "print(\"Total tokens to extract profiles and chapters:\", important_page_tokens)\n",
    "print(\"\\n__________\\n\")\n",
    "print(\"Profile pages:\", profile_pages)\n",
    "print(\"Chapter pages:\", chapter_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780436d6-8bdc-4b04-a11d-348eb9638225",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_pages = [1]\n",
    "profile_pages = [0]\n",
    "print(f\"{len(volume)}\")\n",
    "print(\"\\n__________\\n\")\n",
    "print(\"Saving important pages to disk for QA...\")\n",
    "save_important_pages(volume, profile_pages, chapter_pages, manga, volume_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_profiles = [volume[i] for i in profile_pages]    \n",
    "jobs = split_volume_into_parts(volume, volume_unscaled, chapter_pages, 1)\n",
    "parts = jobs[\"parts\"]\n",
    "jobs_unscaled = jobs[\"unscaled_images\"]\n",
    "jobs = jobs[\"scaled_images\"]\n",
    "\n",
    "# Summarize the images in the first job\n",
    "response = analyze_images_with_gpt4_vision(character_profiles, jobs[0], client, BASIC_PROMPT, BASIC_INSTRUCTIONS)\n",
    "recap = response.choices[0].message.content\n",
    "tokens = response.usage.total_tokens\n",
    "movie_script = extract_text_and_citations(response.choices[0].message.content, jobs[0], jobs_unscaled[0])\n",
    "\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# iterate thrugh the rest of the jobs while adding context from previous ones\n",
    "for i, job in enumerate(jobs):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    response = analyze_images_with_gpt4_vision(character_profiles, job, client, recap + \"\\n-----\\n\" + BASIC_PROMPT_WITH_CONTEXT, BASIC_INSTRUCTIONS)\n",
    "    recap = recap + \"\\n\\n\" + response.choices[0].message.content\n",
    "    tokens += response.usage.total_tokens\n",
    "    print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "    print(response.choices[0].message.content)\n",
    "    movie_script = movie_script + extract_text_and_citations(response.choices[0].message.content, job, jobs_unscaled[i])\n",
    "\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n_____________\\n\\n\\n\")\n",
    "\n",
    "narration_script = extract_script(movie_script)\n",
    "print(narration_script)\n",
    "print(\"\\n___________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59dbd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_panels(movie_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await make_movie(movie_script, manga, volume_number, narration_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adcb9d2-bf68-4d18-b475-c52145efdd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebb25c-7473-4f55-b20b-0eff66908581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d4cc7-37a5-44d3-9480-b98dae3c8289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7aac2-9860-4eb8-8d54-8a4c34702fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33283437-1e28-43a8-b067-b7b13c412bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6edb8-6850-4418-87aa-b9496e4d140d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
